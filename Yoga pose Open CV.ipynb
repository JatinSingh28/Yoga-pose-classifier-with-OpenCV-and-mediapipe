{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec5ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe opencv-python\n",
    "# !pip3 install tensorflowjs\n",
    "# !pip install protobuf==3.20.*\n",
    "# !pip uninstall mediapipe\n",
    "# !pip install mlserver==1.0.1 grpcio==3.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8b0f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:15.123723: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-30 20:32:15.212847: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-30 20:32:15.213961: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 20:32:16.959098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import tensorflowjs as tfjs\n",
    "# import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ffab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6d1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#   while cap.isOpened():\n",
    "#     success, image = cap.read()\n",
    "#     if not success:\n",
    "#       print(\"Unable to record\")\n",
    "#       continue\n",
    "#     image.flags.writeable = False\n",
    "#     image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB )\n",
    "#     results = pose.process(image)\n",
    "\n",
    "#     image.flags.writeable = True\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec = mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "#     cv2.imshow('MediaPipe Pose', cv2.flip(image,1))\n",
    "\n",
    "#     if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "#       break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c71462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "#     left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "#     right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "#     center = left * 0.5 + right * 0.5\n",
    "#     return center\n",
    "\n",
    "\n",
    "# def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "#     hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "#                                  BodyPart.RIGHT_HIP)\n",
    "\n",
    "#   # Shoulders center\n",
    "#     shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "#                                       BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "#   # Torso size as the minimum body size\n",
    "#     torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "\n",
    "#   # Pose center\n",
    "#     pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "#                                      BodyPart.RIGHT_HIP)\n",
    "#     pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "#   # Broadcast the pose center to the same size as the landmark vector to\n",
    "#   # perform substraction\n",
    "#     pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "#                                     [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "#   # Dist to pose center\n",
    "#     d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "#                 name=\"dist_to_pose_center\")\n",
    "#   # Max dist to pose center\n",
    "#     max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "#   # Normalize scale\n",
    "#     pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "#     return pose_size\n",
    "\n",
    "\n",
    "# def normalize_pose_landmarks(landmarks):\n",
    "#     pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "#                                  BodyPart.RIGHT_HIP)\n",
    "#     pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "#   # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "#   # substraction\n",
    "#     pose_center = tf.broadcast_to(pose_center, \n",
    "#                                 [tf.size(landmarks) // (17*2), 17, 2])\n",
    "#     landmarks = landmarks - pose_center\n",
    "\n",
    "#   # Scale the landmarks to a constant pose size\n",
    "#     pose_size = get_pose_size(landmarks)\n",
    "#     landmarks /= pose_size\n",
    "\n",
    "#     return landmarks\n",
    "\n",
    "\n",
    "# def landmarks_to_embedding(landmarks_and_scores):\n",
    "#     reshaped_inputs = keras.layers.Reshape((33, 3))(landmarks_and_scores)\n",
    "\n",
    "#   # Normalize landmarks 2D\n",
    "#     landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "\n",
    "#   # Flatten the normalized landmark coordinates into a vector\n",
    "#     embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "#     return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2659e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "#     left = tf.gather(landmarks, left_bodypart, 1)\n",
    "#     right = tf.gather(landmarks, right_bodypart, 1)\n",
    "#     center = tf.add(tf.mul(left, 0.5), tf.mul(right, 0.5))\n",
    "#     return center\n",
    "  \n",
    "\n",
    "# def get_pose_size(landmarks, torso_size_multiplier = 2.5):\n",
    "#     hips_center = get_center_point(\n",
    "#       landmarks,\n",
    "#       POINTS.LEFT_HIP,\n",
    "#       POINTS.RIGHT_HIP\n",
    "#     )\n",
    "#     shoulders_center = get_center_point(\n",
    "#       landmarks,\n",
    "#       POINTS.LEFT_SHOULDER,\n",
    "#       POINTS.RIGHT_SHOULDER\n",
    "#     )\n",
    "#     torso_size = tf.norm(tf.sub(shoulders_center, hips_center))\n",
    "#     pose_center_new = get_center_point(\n",
    "#       landmarks,\n",
    "#       POINTS.LEFT_HIP,\n",
    "#       POINTS.RIGHT_HIP\n",
    "#     )\n",
    "#     pose_center_new = tf.expandDims(pose_center_new, 1)\n",
    "\n",
    "# #     // pose_center_new = tf.broadcastTo(pose_center_new, [1, 17, 2]);\n",
    "# #     // return: shape(17,2)\n",
    "#     d = tf.gather(tf.sub(landmarks, pose_center_new), 0, 0)\n",
    "#     max_dist = tf.max(tf.norm(d, \"euclidean\", 0))\n",
    "\n",
    "# #     // normalize scale\n",
    "#     pose_size = tf.maximum(\n",
    "#       tf.mul(torso_size, torso_size_multiplier),\n",
    "#       max_dist\n",
    "#     )\n",
    "#     return pose_size\n",
    "\n",
    "# def normalize_pose_landmarks(landmarks):\n",
    "#     pose_center = get_center_point(\n",
    "#       landmarks,\n",
    "#       POINTS.LEFT_HIP,\n",
    "#       POINTS.RIGHT_HIP\n",
    "#     )\n",
    "#     pose_center = tf.expandDims(pose_center, 1)\n",
    "# #     // pose_center = tf.broadcastTo(pose_center, [1, 17, 2])\n",
    "#     landmarks = tf.sub(landmarks, pose_center)\n",
    "\n",
    "#     pose_size = get_pose_size(landmarks)\n",
    "#     landmarks = tf.div(landmarks, pose_size)\n",
    "#     return landmarks\n",
    "\n",
    "# def landmarks_to_embedding(landmarks):\n",
    "# #     // normalize landmarks 2D\n",
    "#     landmarks = normalize_pose_landmarks(tf.expandDims(landmarks, 0))\n",
    "#     embedding = tf.reshape(landmarks, [1, 99])\n",
    "# #     // console.log(embedding.array().then((data) => console.log(data)));\n",
    "#     return embedding\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab104027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to generate pose coordinate\n",
    "# csv_out_path = 'pose_coordinate.csv'\n",
    "# with open(csv_out_path, 'w') as csv_out_file:\n",
    "#     csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "#     basepath = 'train'\n",
    "#     for entry in os.listdir(basepath):\n",
    "#         folder_path = os.path.join(basepath, entry)\n",
    "#         for img in os.listdir(folder_path):\n",
    "#             with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#                 image_path = os.path.join(folder_path,img)\n",
    "#                 image = cv2.imread(image_path)\n",
    "\n",
    "#                 image.flags.writeable = False\n",
    "#                 image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB )\n",
    "#                 result = pose.process(image)\n",
    "#                 pose_landmarks = result.pose_landmarks\n",
    "#                 output_frame = image.copy()\n",
    "                \n",
    "#                 if pose_landmarks is not None:\n",
    "#                     # Check the number of landmarks and take pose landmarks.\n",
    "#                     assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "#                     pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "\n",
    "#                     # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "#                     # correct aspect ratio.\n",
    "#                     frame_height, frame_width = output_frame.shape[:2]\n",
    "#                     pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "#                     # Write pose sample to CSV.\n",
    "#                     pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "#                     csv_out_writer.writerow([img, entry] + pose_landmarks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338d3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_center_point(pose_landmarks):\n",
    "#     left_hip = pose_landmarks.landmark[23]\n",
    "#     right_hip = pose_landmarks.landmark[24]\n",
    "#     hip_center_x = (left_hip.x + right_hip.x)*0.5;\n",
    "#     hip_center_y = (left_hip.y + right_hip.y)*0.5;\n",
    "                    \n",
    "#     left_shoulder = pose_landmarks.landmark[11]\n",
    "#     right_shoulder = pose_landmarks.landmark[12]\n",
    "#     shoulder_center_x = (left_shoulder.x + right_shoulder.x)*0.5;\n",
    "#     shoulder_center_y = (left_shoulder.y + right_shoulder.y)*0.5;\n",
    "                    \n",
    "#     torso_center_x = (hip_center_x + shoulder_center_x )*0.5;\n",
    "#     torso_center_y = (hip_center_y + shoulder_center_y )*0.5;\n",
    "\n",
    "#     return torso_center_x, torso_center_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a952f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(landmarks,pose_center_new):\n",
    "#     d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "#                 name=\"dist_to_pose_center\")\n",
    "#       # Max dist to pose center\n",
    "#     max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "#       # Normalize scale\n",
    "#     pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c19889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csv_out_path = 'pose_coordinate.csv'\n",
    "# with open(csv_out_path, 'w') as csv_out_file:\n",
    "#     csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "#     basepath = 'train'\n",
    "#     for entry in os.listdir(basepath):\n",
    "#         folder_path = os.path.join(basepath, entry)\n",
    "#         for img in os.listdir(folder_path):\n",
    "#             with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#                 image_path = os.path.join(folder_path,img)\n",
    "#                 image = cv2.imread(image_path)\n",
    "\n",
    "#                 image.flags.writeable = False\n",
    "#                 image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB )\n",
    "#                 result = pose.process(image)\n",
    "#                 pose_landmarks = result.pose_landmarks\n",
    "#                 output_frame = image.copy()\n",
    "                \n",
    "#                 if pose_landmarks is not None:\n",
    "#                     torso_center_x, torso_center_y = get_center_point(pose_landmarks)\n",
    "#                     print(torso_center_x, torso_center_y)\n",
    "# #                     # Check the number of landmarks and take pose landmarks.\n",
    "#                     assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "#                     pose_landmarks = [[lmk.x - torso_center_x, lmk.y - torso_center_y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "\n",
    "#                     # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "#                     # correct aspect ratio.\n",
    "#                     frame_height, frame_width = output_frame.shape[:2]\n",
    "#                     pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "#                     # Write pose sample to CSV.\n",
    "#                     pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "#                     csv_out_writer.writerow([img, entry] + pose_landmarks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863dcc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csv_out_path = 'pose_coordinate.csv'\n",
    "# with open(csv_out_path, 'w') as csv_out_file:\n",
    "#     csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "#     basepath = 'train'\n",
    "#     for entry in os.listdir(basepath):\n",
    "#         folder_path = os.path.join(basepath, entry)\n",
    "#         for img in os.listdir(folder_path):\n",
    "#             with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#                 image_path = os.path.join(folder_path,img)\n",
    "#                 image = cv2.imread(image_path)\n",
    "\n",
    "#                 image.flags.writeable = False\n",
    "#                 image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB )\n",
    "#                 result = pose.process(image)\n",
    "#                 pose_landmarks = result.pose_landmarks\n",
    "#                 output_frame = image.copy()\n",
    "                \n",
    "#                 if pose_landmarks is not None:\n",
    "# #                     torso_center_x, torso_center_y = get_center_point(pose_landmarks)\n",
    "# #                     print(torso_center_x, torso_center_y)\n",
    "# #                     # Check the number of landmarks and take pose landmarks.\n",
    "#                     assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "#                     pose_landmarks = [[lmk.x , lmk.y , lmk.z] for lmk in pose_landmarks.landmark]\n",
    "#                     pose_landmarks = landmarks_to_embedding(pose_landmarks)\n",
    "#                     # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "#                     # correct aspect ratio.\n",
    "#                     frame_height, frame_width = output_frame.shape[:2]\n",
    "#                     pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "#                     # Write pose sample to CSV.\n",
    "#                     pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
    "#                     csv_out_writer.writerow([img, entry] + pose_landmarks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8164f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pose_coordinate.csv',names=[x for x in range(101)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2515fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>girl1_chair070.jpg</td>\n",
       "      <td>chair</td>\n",
       "      <td>161.93193</td>\n",
       "      <td>91.50034</td>\n",
       "      <td>-113.45271</td>\n",
       "      <td>161.39712</td>\n",
       "      <td>86.31226</td>\n",
       "      <td>-106.83022</td>\n",
       "      <td>161.58342</td>\n",
       "      <td>86.05865</td>\n",
       "      <td>...</td>\n",
       "      <td>151.52425</td>\n",
       "      <td>145.37344</td>\n",
       "      <td>263.04284</td>\n",
       "      <td>35.51275</td>\n",
       "      <td>164.25312</td>\n",
       "      <td>266.42942</td>\n",
       "      <td>134.10185</td>\n",
       "      <td>161.96825</td>\n",
       "      <td>272.50385</td>\n",
       "      <td>2.88960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girl1_chair070_flipped.jpg</td>\n",
       "      <td>chair</td>\n",
       "      <td>139.86855</td>\n",
       "      <td>91.82668</td>\n",
       "      <td>-104.83980</td>\n",
       "      <td>143.78042</td>\n",
       "      <td>87.16641</td>\n",
       "      <td>-108.79897</td>\n",
       "      <td>145.48917</td>\n",
       "      <td>87.27382</td>\n",
       "      <td>...</td>\n",
       "      <td>48.08073</td>\n",
       "      <td>150.45469</td>\n",
       "      <td>237.26957</td>\n",
       "      <td>172.43419</td>\n",
       "      <td>138.36648</td>\n",
       "      <td>272.82157</td>\n",
       "      <td>21.53601</td>\n",
       "      <td>134.58295</td>\n",
       "      <td>257.23835</td>\n",
       "      <td>168.02629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl1_chair075.jpg</td>\n",
       "      <td>chair</td>\n",
       "      <td>167.14772</td>\n",
       "      <td>99.77740</td>\n",
       "      <td>-93.39951</td>\n",
       "      <td>166.52445</td>\n",
       "      <td>95.02889</td>\n",
       "      <td>-87.08542</td>\n",
       "      <td>166.49821</td>\n",
       "      <td>94.65935</td>\n",
       "      <td>...</td>\n",
       "      <td>133.62957</td>\n",
       "      <td>146.21243</td>\n",
       "      <td>266.85129</td>\n",
       "      <td>35.65139</td>\n",
       "      <td>168.46964</td>\n",
       "      <td>268.35528</td>\n",
       "      <td>129.69736</td>\n",
       "      <td>168.64370</td>\n",
       "      <td>275.69879</td>\n",
       "      <td>28.96146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>girl1_chair075_flipped.jpg</td>\n",
       "      <td>chair</td>\n",
       "      <td>136.16109</td>\n",
       "      <td>100.78100</td>\n",
       "      <td>-76.01230</td>\n",
       "      <td>139.12286</td>\n",
       "      <td>96.90815</td>\n",
       "      <td>-79.26770</td>\n",
       "      <td>140.43436</td>\n",
       "      <td>96.86092</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.07904</td>\n",
       "      <td>145.33850</td>\n",
       "      <td>236.36127</td>\n",
       "      <td>128.01884</td>\n",
       "      <td>133.34532</td>\n",
       "      <td>273.72544</td>\n",
       "      <td>-64.76517</td>\n",
       "      <td>132.31215</td>\n",
       "      <td>257.97881</td>\n",
       "      <td>127.25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>girl1_chair076.jpg</td>\n",
       "      <td>chair</td>\n",
       "      <td>168.41848</td>\n",
       "      <td>104.34607</td>\n",
       "      <td>-96.49125</td>\n",
       "      <td>168.76974</td>\n",
       "      <td>99.73064</td>\n",
       "      <td>-89.25885</td>\n",
       "      <td>169.08849</td>\n",
       "      <td>99.53190</td>\n",
       "      <td>...</td>\n",
       "      <td>119.36260</td>\n",
       "      <td>146.60322</td>\n",
       "      <td>268.53570</td>\n",
       "      <td>22.31681</td>\n",
       "      <td>169.18559</td>\n",
       "      <td>264.90762</td>\n",
       "      <td>118.56466</td>\n",
       "      <td>172.15129</td>\n",
       "      <td>276.03448</td>\n",
       "      <td>13.66442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0      1          2          3          4     \n",
       "0          girl1_chair070.jpg  chair  161.93193   91.50034 -113.45271  \\\n",
       "1  girl1_chair070_flipped.jpg  chair  139.86855   91.82668 -104.83980   \n",
       "2          girl1_chair075.jpg  chair  167.14772   99.77740  -93.39951   \n",
       "3  girl1_chair075_flipped.jpg  chair  136.16109  100.78100  -76.01230   \n",
       "4          girl1_chair076.jpg  chair  168.41848  104.34607  -96.49125   \n",
       "\n",
       "         5         6          7          8         9    ...        91    \n",
       "0  161.39712  86.31226 -106.83022  161.58342  86.05865  ...  151.52425  \\\n",
       "1  143.78042  87.16641 -108.79897  145.48917  87.27382  ...   48.08073   \n",
       "2  166.52445  95.02889  -87.08542  166.49821  94.65935  ...  133.62957   \n",
       "3  139.12286  96.90815  -79.26770  140.43436  96.86092  ...  -41.07904   \n",
       "4  168.76974  99.73064  -89.25885  169.08849  99.53190  ...  119.36260   \n",
       "\n",
       "         92         93         94         95         96         97    \n",
       "0  145.37344  263.04284   35.51275  164.25312  266.42942  134.10185  \\\n",
       "1  150.45469  237.26957  172.43419  138.36648  272.82157   21.53601   \n",
       "2  146.21243  266.85129   35.65139  168.46964  268.35528  129.69736   \n",
       "3  145.33850  236.36127  128.01884  133.34532  273.72544  -64.76517   \n",
       "4  146.60322  268.53570   22.31681  169.18559  264.90762  118.56466   \n",
       "\n",
       "         98         99         100  \n",
       "0  161.96825  272.50385    2.88960  \n",
       "1  134.58295  257.23835  168.02629  \n",
       "2  168.64370  275.69879   28.96146  \n",
       "3  132.31215  257.97881  127.25959  \n",
       "4  172.15129  276.03448   13.66442  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70ff6e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 101)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b00006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "       ...\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100],\n",
       "      dtype='int64', length=101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5ed876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(0,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "891207c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 161.93193,   91.50034, -113.45271, ...,  161.96825,  272.50385,\n",
       "           2.8896 ],\n",
       "       [ 139.86855,   91.82668, -104.8398 , ...,  134.58295,  257.23835,\n",
       "         168.02629],\n",
       "       [ 167.14772,   99.7774 ,  -93.39951, ...,  168.6437 ,  275.69879,\n",
       "          28.96146],\n",
       "       ...,\n",
       "       [ 160.03075,  101.21098, -275.6927 , ...,  169.06106,   76.79547,\n",
       "          44.96757],\n",
       "       [ 135.92988,   85.11297, -182.00737, ...,  134.54167,  275.22699,\n",
       "          46.33296],\n",
       "       [ 164.71746,   97.26677, -219.01392, ...,  180.18463,  104.69069,\n",
       "         416.26228]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71e7b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68ee93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [x for x in df[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26dfc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04042b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "098c2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = le.transform(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f55a412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chair', 'cobra', 'dog', 'no_pose', 'shoudler_stand', 'traingle',\n",
       "       'tree', 'warrior'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44023fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec41e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8892c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(lis,num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3332596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38fbce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd3b4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5fc752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572, 99)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ceb26249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 99)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dad59e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               25600     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,337\n",
      "Trainable params: 67,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=x.shape[1]))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39616c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=20, min_delta =0.1 ,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25a0031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "63/63 [==============================] - 2s 8ms/step - loss: 23.0216 - accuracy: 0.4294\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 4.2347 - accuracy: 0.6088\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.6709 - accuracy: 0.6838\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.7223 - accuracy: 0.7316\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3988 - accuracy: 0.7449\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1487 - accuracy: 0.7729\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8692 - accuracy: 0.8174\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.8416\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.8524\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7582 - accuracy: 0.8257\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6109 - accuracy: 0.8429\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.8830\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8683\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8849\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8982\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8874\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2899 - accuracy: 0.9154\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.2646 - accuracy: 0.9160\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3359 - accuracy: 0.9059\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2252 - accuracy: 0.9205\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2535 - accuracy: 0.9249\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2927 - accuracy: 0.9090\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9211\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.9281\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2423 - accuracy: 0.9300\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9275\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2423 - accuracy: 0.9268\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1738 - accuracy: 0.9389\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.9237\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2409 - accuracy: 0.9256\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9587\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1885 - accuracy: 0.9427\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2577 - accuracy: 0.9186\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1847 - accuracy: 0.9377\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9504\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1754 - accuracy: 0.9466\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9542\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1541 - accuracy: 0.9510\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9631\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9517\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1640 - accuracy: 0.9517\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1991 - accuracy: 0.9338\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9580\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2147 - accuracy: 0.9389\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.9230\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.9434\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.9370\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=25,epochs=1000,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3789f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:46.099272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:46.139469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:46.667256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:46.761383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c6ca755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99713182e-01, 2.91081747e-13, 7.87485233e-22, ...,\n",
       "        2.49618215e-10, 2.86793365e-04, 6.05734924e-23],\n",
       "       [1.02918683e-12, 1.07274745e-09, 9.99997079e-01, ...,\n",
       "        7.54216203e-11, 2.66668359e-08, 3.62485281e-12],\n",
       "       [1.28606274e-14, 6.47582031e-13, 9.99999940e-01, ...,\n",
       "        1.53624794e-17, 3.05535069e-10, 8.96806150e-20],\n",
       "       ...,\n",
       "       [1.06840209e-26, 1.42640563e-19, 1.00000000e+00, ...,\n",
       "        2.47363176e-26, 7.71170162e-17, 1.47709567e-26],\n",
       "       [5.97830621e-34, 5.18588126e-28, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [5.63034860e-07, 9.04343307e-01, 2.76073824e-05, ...,\n",
       "        3.59806000e-12, 9.56285670e-02, 5.93206817e-10]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "419f06dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19019049406051636, 0.9656488299369812]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e180ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00362732, -0.03299519, -0.06602887, ..., -0.12187836,\n",
       "         -0.08394112,  0.0406397 ],\n",
       "        [-0.13075754, -0.01511293,  0.06115869, ..., -0.06858579,\n",
       "         -0.01144459, -0.02603509],\n",
       "        [-0.01057925,  0.0130458 , -0.11499365, ..., -0.11938981,\n",
       "          0.07120433, -0.07885953],\n",
       "        ...,\n",
       "        [-0.09669636,  0.07845997, -0.0203625 , ..., -0.1224263 ,\n",
       "          0.03129628, -0.08159684],\n",
       "        [-0.12634106,  0.05677187,  0.09904908, ..., -0.11248008,\n",
       "         -0.062567  , -0.09240075],\n",
       "        [ 0.10425552, -0.07516393, -0.02837862, ..., -0.13096017,\n",
       "         -0.04646995,  0.02143036]], dtype=float32),\n",
       " array([-3.88248302e-02, -2.23291274e-02, -4.53516915e-02,  1.42791336e-02,\n",
       "        -2.94715445e-02,  8.56748130e-03, -1.38189588e-02, -2.81076394e-02,\n",
       "        -1.56145366e-02, -7.40728993e-03, -4.81512398e-02,  2.01320499e-02,\n",
       "        -5.34381298e-03, -1.73008740e-02, -2.15249360e-02, -1.74675882e-02,\n",
       "         1.95867158e-02, -7.76576623e-03, -9.40593425e-03, -1.41137289e-02,\n",
       "         1.13618083e-03, -9.76427738e-03, -4.89388732e-03, -2.69517698e-03,\n",
       "        -1.67576540e-02,  9.27310344e-03,  1.50565468e-02, -4.53351531e-03,\n",
       "         1.12116020e-02,  1.25093097e-02, -2.06533447e-02, -8.54632724e-03,\n",
       "         8.52986611e-03, -2.99470546e-03,  0.00000000e+00,  1.42740905e-02,\n",
       "        -1.07153067e-02, -5.93806952e-02, -1.37995798e-02, -1.04283672e-02,\n",
       "        -1.70731712e-02,  4.64842888e-03, -1.36881061e-02,  5.72122261e-03,\n",
       "        -9.22591239e-02, -1.43465800e-02,  1.32403998e-02, -5.51003683e-03,\n",
       "        -1.78737063e-02, -4.02251929e-02,  1.24019925e-02, -1.49400383e-02,\n",
       "         2.46248730e-02, -2.08510663e-02,  3.14288698e-02,  2.19995482e-03,\n",
       "        -2.99916212e-02, -4.80549177e-03,  2.59185396e-02, -2.29857564e-02,\n",
       "         1.55762874e-03, -4.02291538e-03, -2.20151041e-02, -2.19622087e-02,\n",
       "         0.00000000e+00, -2.61072125e-02, -3.34976874e-02, -6.62965141e-03,\n",
       "        -1.76775940e-02,  2.00663274e-03, -3.05434018e-02, -7.59514142e-03,\n",
       "        -2.06558732e-03, -1.36258006e-02, -1.25218797e-02, -1.80363171e-02,\n",
       "        -1.65238343e-02, -1.48707479e-02, -1.14340410e-02, -1.54542653e-02,\n",
       "         2.76075006e-02,  7.12865684e-03, -1.55139128e-02, -9.38916765e-03,\n",
       "        -3.05588935e-02, -2.83610169e-02, -8.54357630e-02, -1.41446171e-02,\n",
       "         2.12180540e-02,  2.54635252e-02,  9.99962166e-03, -9.62263439e-03,\n",
       "        -2.58651525e-02, -6.33468619e-03, -4.55298908e-02,  1.42452521e-02,\n",
       "        -2.98985001e-03,  2.57962886e-02,  7.39789149e-03, -7.78716709e-03,\n",
       "         0.00000000e+00, -5.48532233e-03, -4.12795618e-02, -2.78845914e-02,\n",
       "         1.89469196e-02, -1.45899411e-02, -1.06936442e-02, -6.84077758e-03,\n",
       "        -1.25422282e-02,  1.71816275e-02, -1.79403648e-02, -2.46039480e-02,\n",
       "         0.00000000e+00, -5.38882837e-02, -3.49630788e-02, -8.33943486e-03,\n",
       "         3.29999849e-02, -1.08742043e-02, -2.26266906e-02, -2.44818907e-02,\n",
       "        -1.47914328e-02, -4.61059297e-03, -1.90775637e-02, -3.95377539e-02,\n",
       "         7.63444602e-03, -3.83970188e-03,  1.24829495e-03,  4.57811262e-03,\n",
       "        -5.94569044e-03, -2.21301597e-02, -3.55286081e-03, -1.86970122e-02,\n",
       "        -5.24956472e-02, -5.78146335e-03, -2.38340790e-03, -2.08068732e-03,\n",
       "        -2.77962741e-02, -2.69810278e-02, -1.71751119e-02, -5.43987798e-03,\n",
       "        -2.66380273e-02, -4.18440532e-03,  6.23518042e-03,  1.22931981e-02,\n",
       "        -1.05674155e-02, -1.87430326e-02,  1.38630895e-02,  2.40462995e-03,\n",
       "         1.09640891e-02, -4.04667929e-02, -8.54087435e-03, -6.06698403e-03,\n",
       "        -1.47220315e-02, -8.39636475e-03, -9.63771064e-03,  2.03692745e-02,\n",
       "        -6.05575228e-03, -3.05086281e-02, -2.21100096e-02, -6.13216870e-03,\n",
       "         8.90511833e-03, -2.71425601e-02, -1.63575914e-02,  1.43124256e-02,\n",
       "        -5.55808134e-02, -7.71797029e-03,  0.00000000e+00, -7.14901835e-03,\n",
       "         2.28163134e-03, -7.95520376e-03,  6.32886449e-03,  1.01416260e-02,\n",
       "        -3.94080617e-02, -3.15038823e-02, -1.29481470e-02, -1.41324867e-02,\n",
       "        -2.63135182e-03,  1.18662938e-02, -2.04462046e-03, -8.70245881e-03,\n",
       "         3.52790114e-04, -3.13146561e-02,  1.25691760e-03, -5.34464046e-03,\n",
       "        -1.85914582e-03, -1.47407912e-02,  8.92866962e-03, -7.08091678e-03,\n",
       "        -1.51657900e-02, -1.16360979e-02, -9.65902023e-03, -1.10093402e-02,\n",
       "         6.05757860e-03, -1.13402447e-02,  1.07717747e-03, -1.38457427e-02,\n",
       "        -7.70944823e-03, -2.58458052e-02,  2.10912223e-03, -1.59298778e-02,\n",
       "         3.93223483e-03,  1.72911007e-02, -7.98361900e-04,  3.56336939e-03,\n",
       "        -2.13012341e-02, -6.62720902e-03, -2.38633505e-03, -5.06545557e-03,\n",
       "        -2.37331018e-02, -6.93378877e-03,  3.67897004e-02, -4.08684183e-03,\n",
       "        -7.03383377e-03, -7.99157657e-03,  0.00000000e+00, -1.19253043e-02,\n",
       "         8.37062858e-03, -1.43886646e-02, -7.35233165e-03,  0.00000000e+00,\n",
       "        -6.86353212e-03, -9.88545548e-03, -5.36793917e-02,  2.32868791e-02,\n",
       "        -9.16737877e-03, -2.26481166e-02, -1.16429171e-02,  2.16478505e-03,\n",
       "        -1.90290716e-03, -1.47360032e-02, -9.25724022e-03, -5.84090035e-03,\n",
       "        -5.55637199e-03,  1.76104102e-02,  0.00000000e+00, -2.87691713e-03,\n",
       "        -1.85234006e-02, -3.01360991e-02,  4.28474632e-05, -1.48390932e-02,\n",
       "        -1.71081349e-02, -8.70917086e-03, -2.58422978e-02,  8.26532170e-02,\n",
       "        -8.42949003e-03, -1.31422905e-02, -9.26558953e-03, -2.77502835e-02,\n",
       "         7.75658106e-03, -4.69964184e-03, -6.72965543e-03,  2.74395440e-02,\n",
       "        -1.22736907e-02, -1.27236284e-02, -1.19224787e-02,  6.45794487e-03],\n",
       "       dtype=float32),\n",
       " array([[ 0.09336309,  0.06513734,  0.06164916, ..., -0.10024851,\n",
       "         -0.04790318,  0.0964502 ],\n",
       "        [ 0.0311891 ,  0.04733437, -0.10389572, ...,  0.11238552,\n",
       "          0.11954156, -0.10144765],\n",
       "        [ 0.03056993, -0.03144281, -0.09365813, ...,  0.01640461,\n",
       "          0.08432794, -0.09744383],\n",
       "        ...,\n",
       "        [ 0.12552257,  0.00861433, -0.07705268, ..., -0.0244083 ,\n",
       "         -0.01265326, -0.09166444],\n",
       "        [-0.09809516, -0.06373471,  0.08679693, ..., -0.03379722,\n",
       "         -0.01262252,  0.10053502],\n",
       "        [ 0.00707155, -0.08397822,  0.0553354 , ...,  0.11080998,\n",
       "          0.11271887, -0.09837887]], dtype=float32),\n",
       " array([-0.04687634, -0.03957007, -0.0270139 , -0.02854548, -0.03689585,\n",
       "        -0.06110445, -0.03276319, -0.02461953, -0.09910396, -0.08606713,\n",
       "         0.00801434, -0.0109452 , -0.06920917, -0.07962384, -0.05284988,\n",
       "        -0.04551245, -0.03757208,  0.02582564,  0.00127092, -0.02037769,\n",
       "        -0.08387458, -0.03955514, -0.08740217, -0.00339443, -0.00517784,\n",
       "         0.05991174, -0.0558672 ,  0.00295009,  0.01148642, -0.00540722,\n",
       "        -0.06825438, -0.02767337, -0.04041312,  0.08737409, -0.01927426,\n",
       "        -0.02931484, -0.00078749, -0.06997812, -0.08551127, -0.02750188,\n",
       "        -0.0561352 , -0.01355456, -0.01315982, -0.00064496, -0.04313997,\n",
       "        -0.00299965,  0.05284546, -0.05675445, -0.01578295, -0.0703132 ,\n",
       "         0.07754573, -0.04033831, -0.00778819,  0.03956612, -0.04300252,\n",
       "        -0.02660213, -0.03144263, -0.02175833, -0.0713806 , -0.01405422,\n",
       "        -0.00066509,  0.04102483, -0.05013075, -0.05387802, -0.00517342,\n",
       "        -0.01129674, -0.05845372, -0.06699134,  0.02898994, -0.04913878,\n",
       "        -0.04761244, -0.0625504 , -0.09505001,  0.10413638,  0.02061802,\n",
       "        -0.06362312,  0.01600283, -0.13863422, -0.05990474,  0.0147658 ,\n",
       "        -0.00396934,  0.00480219,  0.0754467 ,  0.02911506, -0.01888081,\n",
       "        -0.05213552, -0.0390877 ,  0.08011892, -0.03448705, -0.03282716,\n",
       "        -0.03530297,  0.05451096, -0.01518303,  0.0023372 , -0.05317179,\n",
       "        -0.02183383, -0.03949091, -0.04389355, -0.05250024,  0.04471116,\n",
       "         0.0278005 , -0.02671818, -0.06676615, -0.05993018, -0.04129902,\n",
       "        -0.00823509, -0.00853957, -0.15828724, -0.05968292, -0.06016601,\n",
       "        -0.02276281, -0.03249411, -0.10363439, -0.03700454, -0.07848445,\n",
       "         0.07491651, -0.07855989, -0.066698  , -0.01565552, -0.08638463,\n",
       "        -0.05114036, -0.07201169, -0.03462862, -0.00754034, -0.05462123,\n",
       "         0.01614979, -0.02578346, -0.05040902], dtype=float32),\n",
       " array([[ 0.19158824,  0.13677013, -0.14805228, ..., -0.1518645 ,\n",
       "         -0.09939386,  0.05369542],\n",
       "        [-0.18401022,  0.08428228,  0.18785694, ...,  0.13815628,\n",
       "          0.10272137,  0.00675831],\n",
       "        [-0.12719014, -0.1731525 , -0.07323127, ..., -0.0363306 ,\n",
       "          0.02817831, -0.00667494],\n",
       "        ...,\n",
       "        [-0.03874077, -0.03369325, -0.1221278 , ..., -0.08850046,\n",
       "          0.11781514,  0.15505227],\n",
       "        [-0.18493351, -0.14911816, -0.08171958, ..., -0.24053656,\n",
       "         -0.12516953, -0.0267965 ],\n",
       "        [-0.08504917, -0.06154508, -0.04701813, ..., -0.07440934,\n",
       "         -0.05204633,  0.08876634]], dtype=float32),\n",
       " array([-1.62980407e-01, -9.36091063e-04,  1.01604412e-04,  2.61081997e-02,\n",
       "        -1.10330973e-02,  9.46793929e-02, -5.76576777e-02, -9.63578448e-02,\n",
       "        -6.74274489e-02, -1.87188849e-01, -4.38815281e-02, -7.64089450e-02,\n",
       "        -1.25743798e-03,  1.08327515e-01, -7.19408244e-02, -1.23272531e-01,\n",
       "        -6.88099265e-02, -6.74504787e-02, -3.00393086e-02,  1.20078616e-01,\n",
       "        -5.81106953e-02, -1.08393557e-01,  1.59372956e-01, -1.08685724e-01,\n",
       "         2.02330351e-02, -9.28781405e-02, -3.43253762e-02, -3.11909169e-02,\n",
       "        -7.87703171e-02, -9.61177871e-02, -5.37613779e-02,  3.47251520e-02,\n",
       "         1.64140448e-01, -3.70100699e-02, -1.21957451e-01, -9.36513096e-02,\n",
       "        -1.03968546e-01, -2.63184514e-02,  6.77683651e-02, -6.31476641e-02,\n",
       "         2.40783859e-02, -3.23928753e-03,  6.29748628e-02, -9.05615762e-02,\n",
       "         4.58148541e-03, -7.45338425e-02,  1.70386449e-01, -9.13671553e-02,\n",
       "        -2.24905573e-02, -2.25015745e-01, -8.92746523e-02, -2.00153957e-03,\n",
       "        -1.36265054e-01, -1.75646856e-01,  1.82446688e-02, -7.32177272e-02,\n",
       "        -8.07984844e-02, -1.80891491e-02, -1.00639202e-01, -8.04130659e-02,\n",
       "        -9.84778702e-02, -1.05009101e-01, -3.44834179e-02, -4.47812937e-02],\n",
       "       dtype=float32),\n",
       " array([[-0.23614907, -0.11881594,  0.09765992,  0.18958049,  0.11452346,\n",
       "          0.20091176, -0.19575664, -0.18546657, -0.07640292],\n",
       "        [ 0.06349949,  0.12536374, -0.07567371,  0.02234654, -0.02733478,\n",
       "         -0.13333815, -0.13433112, -0.03645974, -0.27125454],\n",
       "        [-0.25351554, -0.27048698, -0.16281447,  0.00408068,  0.05989153,\n",
       "         -0.12969528,  0.11832592, -0.2509554 ,  0.01018297],\n",
       "        [-0.19165048, -0.21184376,  0.13534437,  0.13599499, -0.21693464,\n",
       "         -0.01537096, -0.00235394, -0.04914245, -0.28075144],\n",
       "        [-0.15957682,  0.12483315,  0.06091413, -0.03524978, -0.21196483,\n",
       "         -0.05087066, -0.07016664, -0.02294402, -0.1090782 ],\n",
       "        [-0.19983712,  0.00170258,  0.10653544, -0.17217863, -0.26706275,\n",
       "         -0.05760515, -0.2117151 ,  0.12815085,  0.10063671],\n",
       "        [-0.02065172, -0.08031331,  0.22246511, -0.11701051, -0.05664385,\n",
       "          0.12011623, -0.2517163 , -0.06973664, -0.27711675],\n",
       "        [ 0.09601756,  0.05966026,  0.06485613, -0.05760529,  0.13599195,\n",
       "          0.20943534,  0.11228907,  0.19766901, -0.25200155],\n",
       "        [-0.24920088,  0.1938516 ,  0.17138407,  0.13784632, -0.03788573,\n",
       "         -0.15145235, -0.03483383, -0.0356902 , -0.17620553],\n",
       "        [ 0.07270765, -0.13860618,  0.11473295, -0.07264452, -0.06095594,\n",
       "          0.21998262,  0.00960888, -0.06361606,  0.10973636],\n",
       "        [-0.20584609, -0.02792259,  0.03988638, -0.13222562,  0.14261428,\n",
       "         -0.11476304, -0.01128414,  0.20479104, -0.26950008],\n",
       "        [ 0.1365595 ,  0.09684947,  0.22758889,  0.1382291 ,  0.11610175,\n",
       "          0.16851951, -0.07980908,  0.10281795, -0.1792999 ],\n",
       "        [ 0.11475711,  0.03798672, -0.06429282, -0.11063652,  0.17085621,\n",
       "         -0.20494458,  0.17763726, -0.11505454, -0.21472788],\n",
       "        [ 0.18991172,  0.10422042,  0.09778625, -0.17167069,  0.01456986,\n",
       "          0.1070902 ,  0.24693897,  0.06898797,  0.24552067],\n",
       "        [-0.26317415, -0.26936918,  0.1738964 , -0.14710428,  0.0499998 ,\n",
       "         -0.09023862,  0.02171735, -0.15963008, -0.25339392],\n",
       "        [-0.0895656 ,  0.1349308 , -0.1946309 , -0.04101463, -0.06484194,\n",
       "          0.19602178, -0.01316139, -0.07522291, -0.01058632],\n",
       "        [ 0.04959522, -0.09962609,  0.16323279, -0.13375488,  0.02849684,\n",
       "          0.18950133,  0.05959061,  0.11846714,  0.12820952],\n",
       "        [ 0.20797151, -0.16553763, -0.1311673 , -0.00272093, -0.11377905,\n",
       "         -0.21951996, -0.12802325,  0.23435141, -0.21407758],\n",
       "        [ 0.23465368,  0.1558256 ,  0.16278385,  0.16862218, -0.01923033,\n",
       "          0.10195503,  0.1722938 ,  0.02280993, -0.10167299],\n",
       "        [-0.18580557, -0.0303284 ,  0.16427912, -0.10688372, -0.29017678,\n",
       "         -0.02072471,  0.05716852, -0.14193794, -0.01088979],\n",
       "        [-0.05599395, -0.21398588,  0.00174268, -0.11851373,  0.24579734,\n",
       "          0.10533801,  0.17446196, -0.08749221, -0.11714786],\n",
       "        [-0.1956387 , -0.11225153,  0.1465747 ,  0.15652312, -0.13961701,\n",
       "          0.21728049, -0.20877771,  0.06212998,  0.17617287],\n",
       "        [ 0.15229985,  0.05415287, -0.15111654,  0.08570768, -0.2120743 ,\n",
       "         -0.00242104,  0.15886056,  0.24752961, -0.15217999],\n",
       "        [ 0.05728283, -0.0727275 , -0.05834571, -0.09635974,  0.12125646,\n",
       "         -0.22061506, -0.24366845, -0.03843459,  0.1532134 ],\n",
       "        [ 0.02461891, -0.0353896 , -0.23510733, -0.03306512, -0.15426059,\n",
       "         -0.07776782, -0.02714035, -0.1329151 ,  0.15512516],\n",
       "        [-0.0202172 , -0.1463927 , -0.15381236,  0.07754468, -0.02840665,\n",
       "         -0.14089586, -0.1031154 , -0.11875141,  0.0186646 ],\n",
       "        [-0.0979086 ,  0.15230973,  0.2431707 , -0.12993139,  0.22060506,\n",
       "          0.15961331, -0.06314579,  0.04448036,  0.09126902],\n",
       "        [-0.03414546, -0.05384798, -0.20971753, -0.1788805 , -0.21103731,\n",
       "         -0.04288699, -0.07661428,  0.03966141,  0.1534461 ],\n",
       "        [ 0.14071839,  0.08632974, -0.01141929,  0.07423715,  0.07921286,\n",
       "         -0.07755266, -0.14623237,  0.01812356,  0.14111021],\n",
       "        [ 0.16459471, -0.1811006 ,  0.03450362,  0.13692857, -0.0113851 ,\n",
       "          0.24301076,  0.18509547, -0.02829746, -0.15835463],\n",
       "        [-0.03754489,  0.06344483, -0.11964182, -0.14737329, -0.18788804,\n",
       "          0.10933714,  0.08078022, -0.12848601, -0.0870536 ],\n",
       "        [ 0.18973488,  0.22181526, -0.06070019,  0.12951073,  0.20355229,\n",
       "         -0.16402297,  0.26497534, -0.1669185 , -0.25013876],\n",
       "        [ 0.02835474, -0.21445408, -0.05756732, -0.15957798, -0.08496802,\n",
       "         -0.03499451,  0.21037489, -0.19540389, -0.21897961],\n",
       "        [ 0.08988577,  0.24495552, -0.1317771 , -0.11247388,  0.20965293,\n",
       "         -0.06732862, -0.24608058,  0.11499733, -0.26436135],\n",
       "        [-0.20784722, -0.23329838, -0.10170689,  0.00848768,  0.18150203,\n",
       "          0.23282644,  0.1784922 ,  0.0741125 , -0.01145843],\n",
       "        [ 0.1923684 , -0.21784271, -0.04007582,  0.21652085,  0.08755776,\n",
       "          0.1028562 ,  0.19821446, -0.0527872 , -0.19923475],\n",
       "        [-0.11759349, -0.1092893 , -0.15160328, -0.22548322,  0.20399411,\n",
       "         -0.21932507, -0.14016826,  0.03625041,  0.07986534],\n",
       "        [ 0.17457911, -0.14830266, -0.08574597, -0.18139657,  0.19165291,\n",
       "         -0.11288694,  0.03512461,  0.23639183,  0.23469284],\n",
       "        [ 0.24318498,  0.26804402,  0.00626357,  0.15454316,  0.09086501,\n",
       "         -0.02193073,  0.23513699,  0.11176462, -0.20726427],\n",
       "        [ 0.02847005,  0.04793119,  0.10103248, -0.04466069,  0.26661828,\n",
       "          0.09396243,  0.12263995,  0.1206056 , -0.02511596],\n",
       "        [-0.17197366,  0.16473475,  0.20454223, -0.17606536,  0.24236359,\n",
       "         -0.1604519 ,  0.14269064,  0.21516456, -0.17096624],\n",
       "        [-0.02090393,  0.02686393, -0.23307334,  0.01849444, -0.1578871 ,\n",
       "         -0.04825175,  0.08527975, -0.15904495,  0.09296648],\n",
       "        [ 0.10072143,  0.1756045 , -0.29519844, -0.10375568, -0.23599158,\n",
       "          0.03626366,  0.15315747, -0.0500521 ,  0.1624292 ],\n",
       "        [-0.08972011,  0.18013728, -0.19827822, -0.23709722,  0.00968278,\n",
       "          0.04088486,  0.14869033, -0.04351591, -0.03740592],\n",
       "        [-0.27306148, -0.03629854,  0.0327254 ,  0.0668173 , -0.13695465,\n",
       "         -0.09972508, -0.04380992,  0.09837983,  0.1120418 ],\n",
       "        [ 0.04631798,  0.25815806,  0.2110428 ,  0.17859535,  0.07784161,\n",
       "          0.07594085, -0.16157322, -0.21637064, -0.11301413],\n",
       "        [ 0.04902605,  0.17787163,  0.21531153, -0.20674948,  0.17978805,\n",
       "         -0.12623972,  0.05884963,  0.2365886 ,  0.16424528],\n",
       "        [ 0.10573538,  0.07314938,  0.01711241, -0.00675882,  0.1716729 ,\n",
       "          0.01975492, -0.07660062, -0.11073204, -0.08696117],\n",
       "        [ 0.07241322,  0.24009964, -0.13823159, -0.20911321,  0.14544687,\n",
       "          0.17217739,  0.15613084,  0.16775902, -0.02582545],\n",
       "        [-0.03487698, -0.11184322, -0.04424819,  0.05020012, -0.19173013,\n",
       "          0.17821158, -0.18734705, -0.13262229,  0.2595145 ],\n",
       "        [-0.05924214,  0.15513396, -0.24914046, -0.19875073, -0.16932368,\n",
       "          0.08310919, -0.24302493,  0.1851245 , -0.2072654 ],\n",
       "        [-0.07365019, -0.00031054,  0.24441487, -0.23218562, -0.27129397,\n",
       "         -0.23535231, -0.1669567 , -0.02829499,  0.10517853],\n",
       "        [ 0.16573979,  0.22611865,  0.1951743 ,  0.21736366,  0.18172048,\n",
       "          0.21392013, -0.2022515 ,  0.17091279,  0.05186507],\n",
       "        [-0.27364618, -0.15293373,  0.0738717 , -0.18957546,  0.05130849,\n",
       "          0.23408861,  0.1167405 , -0.0700921 , -0.08533146],\n",
       "        [ 0.13571328,  0.12281476, -0.14344531, -0.18925568,  0.17969649,\n",
       "         -0.15713975,  0.04774844, -0.20741108,  0.02602329],\n",
       "        [ 0.04963419, -0.24288976,  0.0301778 ,  0.05698382,  0.23725013,\n",
       "         -0.17377824, -0.20205756, -0.24320242,  0.08833393],\n",
       "        [-0.22095568, -0.01900335, -0.23145896, -0.04207641, -0.02968509,\n",
       "         -0.15479627,  0.08769919, -0.0425706 ,  0.2260528 ],\n",
       "        [-0.13353844, -0.04559703,  0.21291605, -0.1915623 ,  0.03572409,\n",
       "         -0.10191697, -0.22845078, -0.153733  ,  0.12890644],\n",
       "        [ 0.04293473,  0.14559175, -0.25016043,  0.21380553,  0.16864808,\n",
       "         -0.0852612 ,  0.01366799, -0.21946992,  0.01574679],\n",
       "        [-0.24604627,  0.05958712, -0.1936388 ,  0.10639779, -0.08804788,\n",
       "         -0.22171754,  0.05592672, -0.12057579,  0.16837417],\n",
       "        [-0.00708285, -0.19292364,  0.18904413, -0.1808929 ,  0.02406666,\n",
       "         -0.16870676,  0.14875388, -0.13809252,  0.03871668],\n",
       "        [ 0.15439431,  0.1830893 , -0.06899224, -0.04190237,  0.10961919,\n",
       "          0.04969632,  0.02262528, -0.04170353,  0.02349338],\n",
       "        [ 0.15736505, -0.15411457, -0.26925176,  0.13373815,  0.12316126,\n",
       "         -0.06215354,  0.10510738, -0.13456242, -0.01886824],\n",
       "        [ 0.20181338,  0.01495897, -0.18863574,  0.06743748,  0.2071151 ,\n",
       "          0.14516075,  0.13297512,  0.21729386,  0.01818915]],\n",
       "       dtype=float32),\n",
       " array([ 0.06226391,  0.05172672,  0.09664192, -0.1546477 , -0.20366776,\n",
       "        -0.37959486,  0.16776522,  0.05733332, -0.10562975], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60e79448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:49.621296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:49.659354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:50.221143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:50.353234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df97fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 99)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(x_test[0],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "534fcefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8644501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model_pkl.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8a185ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pkl = pickle.load(open('model_pkl.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdafac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c560d558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9971324e-01, 2.9108457e-13, 7.8749129e-22, 4.7510197e-17,\n",
       "        7.9484831e-17, 3.5542586e-10, 2.4961919e-10, 2.8679392e-04,\n",
       "        6.0573732e-23]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(x_test[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93a00418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = dict(zip(le.classes_, le.transform(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45744796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chair'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54f09986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.3, min_tracking_confidence=0.3) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Unable to record\")\n",
    "            continue\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB )\n",
    "        results = pose.process(image)\n",
    "        pose_landmarks = results.pose_landmarks\n",
    "        output_frame = image.copy()\n",
    "        pose_name = 'Unidentified'\n",
    "        if pose_landmarks is not None:\n",
    "#             torso_center_x, torso_center_y = get_center_point(pose_landmarks)\n",
    "            vector = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "            frame_height, frame_width = output_frame.shape[:2]\n",
    "\n",
    "            vector *= np.array([frame_width, frame_height, frame_width])\n",
    "            vector = vector.flatten()\n",
    "            vector = np.expand_dims(vector,axis=0)\n",
    "\n",
    "            prediction = model.predict((vector))\n",
    "\n",
    "            index = np.argmax(prediction)\n",
    "\n",
    "            pose_name = le.inverse_transform([index])\n",
    "#             print(\"pose name:\",pose_name)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec = mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "        image = cv2.flip(image,1)\n",
    "\n",
    "        #Rectangle\n",
    "        start_point = (0, 0)\n",
    "        end_point = (300, 100)\n",
    "        color = (0, 0, 0)\n",
    "        thickness = -1\n",
    "        image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "        #write\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        org = (25, 50)\n",
    "        fontScale = 1\n",
    "        color = (255, 255, 255)\n",
    "        thickness = 2\n",
    "\n",
    "        image = cv2.putText(image, pose_name[0], org, font, \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('MediaPipe Pose',image)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2143b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d031ffdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chair', 'cobra', 'dog', 'no_pose', 'shoudler_stand', 'traingle',\n",
       "       'tree', 'warrior'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06b7c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_dict={};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bdc9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pose in df[1].unique():\n",
    "    pose_dict[str(le.transform([pose])[0])] = pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5bfdafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['chair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b17177bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'chair',\n",
       " '1': 'cobra',\n",
       " '2': 'dog',\n",
       " '3': 'no_pose',\n",
       " '4': 'shoudler_stand',\n",
       " '5': 'traingle',\n",
       " '6': 'tree',\n",
       " '7': 'warrior'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "695b8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f02ef3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pose_labels.txt','w') as f:\n",
    "    f.write(json.dumps(pose_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cf122ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:32:57.951076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:57.987003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:58.398259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-30 20:32:58.498694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpme5olobj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpme5olobj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 71KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:33:00.544094: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-05-30 20:33:00.544167: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-05-30 20:33:00.545032: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpme5olobj\n",
      "2023-05-30 20:33:00.547453: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-30 20:33:00.547515: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpme5olobj\n",
      "2023-05-30 20:33:00.561122: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-05-30 20:33:00.564835: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-05-30 20:33:00.724716: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpme5olobj\n",
      "2023-05-30 20:33:00.761522: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 216497 microseconds.\n",
      "2023-05-30 20:33:00.807790: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print('Model size: %dKB' % (len(tflite_model) / 1024))\n",
    "\n",
    "with open('pose_classifier.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e8237f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pose_labels.txt', 'w') as f:\n",
    "#   f.write('\\n'.join(df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f83829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59855925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ZipFile('model.zip', 'w') as zipObj:\n",
    "#     zipObj.write('pose_classifier.tflite')\n",
    "#     zipObj.write('pose_labels.txt')\n",
    "#     zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2493f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfjs.converters.save_keras_model(model,'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9acb19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip pose_classifier.zip pose_labels.txt pose_classifier.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25f9e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#   from google.colab import files\n",
    "#   files.download('pose_classifier.zip')\n",
    "# except:\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3eafeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99713182e-01, 2.91081747e-13, 7.87485233e-22, ...,\n",
       "        2.49618215e-10, 2.86793365e-04, 6.05734924e-23],\n",
       "       [1.02918683e-12, 1.07274745e-09, 9.99997079e-01, ...,\n",
       "        7.54216203e-11, 2.66668359e-08, 3.62485281e-12],\n",
       "       [1.28606274e-14, 6.47582031e-13, 9.99999940e-01, ...,\n",
       "        1.53624794e-17, 3.05535069e-10, 8.96806150e-20],\n",
       "       ...,\n",
       "       [1.06840209e-26, 1.42640563e-19, 1.00000000e+00, ...,\n",
       "        2.47363176e-26, 7.71170162e-17, 1.47709567e-26],\n",
       "       [5.97830621e-34, 5.18588126e-28, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [5.63034860e-07, 9.04343307e-01, 2.76073824e-05, ...,\n",
       "        3.59806000e-12, 9.56285670e-02, 5.93206817e-10]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fec9fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1902 - accuracy: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19019049406051636, 0.9656488299369812]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
